---
title: "Statistical Analysis, MSCA 31007, Lecture 3"
author: "Hope Foster-Reyes"
date: "October 28, 2016"
output:
  pdf_document:
    fig_width: 6.5
    fig_height: 4.5
geometry: margin=0.75in
---

# Simulation of 4 Linear Models

Understand common assumptions behind the linear model.

_Notes_

* _Style Guide:_ https://google.github.io/styleguide/Rguide.xml

* _Packages required: None_

* _Files required: None_

## Set Up

Set the values of slope (a) and intercept (b) parameters. Set the sample length to 1,000.

```{r setup}
# Slope and Intercept
a <- 0.8; b <- 0.1
sample.n <- 1000

# Seeds
seed1 <- 111
seed2 <- 1112131415

options(scipen = 5)
```

## Introduction

Let's imagine that X is a normally distributed variable, and Y is a variable which is correlated to X with a simple linear relationship. We can simulate and plot this relationship in R.

Input variable $X \sim Norm(\mu= 3, \sigma=2.5)$

```{r intro}
# Simulate the X variable using rnorm()
set.seed(seed1)
model1.x.sd <- 2.5
model1.x <- rnorm(sample.n, mean = 3, sd = model1.x.sd)

# Simulate a simple introductory model with no residual 
model.intro.y <- (a * model1.x + b) 
model.intro <- data.frame(Y=model.intro.y, X=model1.x)
```


## 1. Model 1

Now we'll take the above simple introductory model and add a Gaussian residual representing variation in Y that is undescribed by our simplistic model above. 

Simulate and plot Model 1:

Input variable $X \sim Norm(\mu= 3, \sigma=2.5)$; model residuals $Eps \sim Norm(\mu = 0, \sigma = 1.5)$

```{r m1, fig.width=6.5, fig.height=4.5}
# Simulate the Eps residual using rnorm()
set.seed(seed2)
model1.eps.sd <- 1.5
model1.eps <- rnorm(sample.n, mean = 0, sd = model1.eps.sd)

model1.y <- (a * model1.x + b) + model1.eps
model1 <- data.frame(Y=model1.y, X=model1.x, Eps=model1.eps)

# Inspect results and compare with our simplistic model
title <- "Intro Model"
plot(model.intro$X, model.intro$Y, main = title, ylim = c(-5, 15))

title <- "Model 1"
head(model1)
plot(model1$X, model1$Y, main = title)
plot(model1$Eps, type = "l", main = paste(title, "Residuals"))
```

## 2. Model 2

Simulate and plot Model 2:

Input variable $X \sim Norm(\mu= 3, \sigma=2.5)$; model residuals $Eps \sim Unif(min=-4.33, max=4.33)$

```{r m2}
# Simulate the model using X from Model 1 and runif() for Eps
set.seed(seed2)
model2.eps <- runif(sample.n, min = -4.33, max = 4.33)

model2.y <- (a * model1.x + b) + model2.eps
model2 <- data.frame(Y=model2.y, X=model1.x, Eps=model2.eps)

# Inspect results
title <- "Model 2"
head(model2)
plot(model2$X, model2$Y, main = title)
plot(model2$Eps, type = "l", main = paste(title, "Residuals"))
```

## 3. Model 3

Simulate and plot Model 3:

Input variable $X \sim Norm(\mu= 3, \sigma=2.5)$; model residuals $Eps \sim Cauchy*(location=0, scale=3)$

```{r m3}
# Simulate the model using X from Model 1 and rcauchy() for Eps
set.seed(seed2)
model3.eps <- rcauchy(sample.n, location = 0, scale = 0.3)

model3.y <- (a * model1.x + b) + model3.eps
model3 <- data.frame(Y=model3.y, X=model1.x, Eps=model3.eps)

# Inspect results
title <- "Model 3"
head(model3)
plot(model3$X, model3$Y, main = title)
plot(model3$Eps, type = "l", main = paste(title, "Residuals"))
```

Here it appears that we've lost our correlation entirely due to the shape appearing with no slope in our plot of Model 3. Let's take a closer look by plotting the model with the same scale as our previous models. We'll lose several of our Y outliers from the display, but we'll get a closer look at the center of our Y values.

Just to keep our bearings, we'll compare this to our original simplistic model with no residuals.

```{r m3-zoom}
plot(model3$X, model3$Y, main = paste(title, "Zoomed In"), 
     ylim = c(-5, 15))
title <- "Intro Model"
plot(model.intro$X, model.intro$Y, main = title, ylim = c(-5, 15))
```

Estimate the standard deviation of the residuals.

```{r m3-sd}
(sd(model3$Eps))
```

Generate another 5 samples of residuals without any seed specification and estimate standard deviations for each of them.

```{r m3-residuals}
model3.eps1 <- rcauchy(sample.n, location = 0, scale = 0.3)
model3.eps2 <- rcauchy(sample.n, location = 0, scale = 0.3)
model3.eps3 <- rcauchy(sample.n, location = 0, scale = 0.3)
model3.eps4 <- rcauchy(sample.n, location = 0, scale = 0.3)
model3.eps5 <- rcauchy(sample.n, location = 0, scale = 0.3)
c(sd(model3.eps1), sd(model3.eps2), sd(model3.eps3), sd(model3.eps4), sd(model3.eps5))
```

Note the irregularity of standard deviations from sample to sample.

***How do you interpret this observation?***

The Cauchy distribution is unique in that its expected value, i.e. mean, and other moments of any order n >= 1 do not exist. For example, in contrast with a Cauchy, for the normal distribution we can define parameters which will result in theoretical moments. For any adequately large sample based on this specific distribution (i.e. these specific parameters), the sample will demonstrate moments (which may be calculated using its moment generating function) which are close to the theoretical moments, and which, as the sample becomes larger and larger, will converge on those moments.

Unlike the normal distribution and other typical families of distributions, the Cauchy family of distributions does not demonstrate this same quality. There is no moment generating function and therefore no theoretical moments. While we may still calculate a number for the mean or standard deviation of an individual sample using the common formulas, these numbers will not bear any consistency or resemblance to any theoretical mean or standard deviation, as for Cauchy distributions these do not exist. 

Similarly, generating multiple samples over time will not demonstrate consistency between the mean and standard deviations of the individual samples, nor demonstrate a normal sampling distribution. Thus the qualities of a sampling distribution taken from a Cauchy distribution is an exception to the Central Limit Theorem.

## 4. Model 4

Simulate and plot Model 4:

Input variable $X \sim Norm(\mu= 3, \sigma=2.5)$; model residuals $Eps \sim$ a heteroscedastic process.

Heteroscedasticity means that even though the model residuals Eps may be generated by a normal distribution, the standard deviation parameters for different sub samples are different.

Create the process of standard deviations in which the first 50 observations have sigma=2, followed by 75 observations with sigma=3.4, followed by 75 observations with sigma=0.8 and concluded by 50 observations with sigma=2.6.

Plot the trajectory of standard deviations of total length nSample=1000.

```{r m4-residuals}
# Create heteroscedastic process
hetero.sd <- c(2, 3.4, 0.8, 2.6)
hetero.loop <- c(rep(hetero.sd[1], 50),
                 rep(hetero.sd[2], 75),
                 rep(hetero.sd[3], 75),
                 rep(hetero.sd[4], 50))
hetero.process <- rep(hetero.loop, 4)
plot(hetero.process, type = "l")

# Simulate the linear model residuals Eps with changing standard deviations.
set.seed(seed2)
model4.eps <- rnorm(sample.n) * hetero.process

# Plot the residuals
title <- "Model 4"
plot(model4.eps, type = "l", main = paste(title, "Residuals"))
```

Observe how heteroscedasticity transforms normal distribution into leptokurtic distribution.

```{r m4-demo}
hetero.x <- (100 * floor(min(model4.eps))) : (100 * ceiling(max(model4.eps)))
hetero.x <- hetero.x / 100

# Plot the theoretical distribution
plot(hetero.x, dnorm(hetero.x, mean = mean(model4.eps), sd = sd(model4.eps)), 
     type = "l", ylim = c(0, 0.3), col = "black", 
     ylab = "Distribution of Heteroscedastic Eps")

# And the heteroscedastic sample distribution
lines(density(model4.eps), col = "Red")
```

Generate Model 4 and plot. Plot our Model 1 again with the same scale to observe the differences side by side.

```{r m4}
# Simulate the model using X from Model 1 and heteroscedastic residuals
model4.y <- (a * model1.x + b) + model4.eps
model4 <- data.frame(Y=model4.y, X=model1.x, Eps=model4.eps)

# Inspect results
plot(model4$X, model4$Y, main = title)
plot(model1$X, model1$Y, main = "Model 1", ylim = c(-9, 18))
```

## 5. Effect of Residual Distribution on Correlation

Calculate the theoretical $\rho^{2}$ for the “correct model” which is Model 1.

```{r q5-theoretical}
# Calculate squared correlation coefficient using the parameters specified 
#   for Model 1 X and Eps
(rho.sq.theoretical <- (a * model1.x.sd)^2 / ((a * model1.x.sd)^2 + model1.eps.sd^2))
```

And compare with the estimated $\rho^{2}$

```{r q5-simulated}
c(cor(model1$X, model1$Y)^2,
  cor(model2$X, model2$Y)^2,
  cor(model3$X, model3$Y)^2,
  cor(model4$X, model4$Y)^2)
```

***How do you interpret the results?***

*For Model 1:*

Our correlation is close to the theoretical distribution, predictably since it is a simulated sample from that model.

*For Model 2:*

We still see a strong correlation but it is weaker than Model 1. This we can also expect since the residual is "more spread out". The residual from Model one was based on a normal distribution, therefore the residual values, and resultant Y values, were largely packed very close to the correlated x,y line, as in a normal distribution most of the values (the top of the bell curve) are close to the mean. 

A unified distribution, however, does not have most of its values close to the mean, instead its values are evenly distributed. Therefore when our residual distribution was based on a unified distribution, the resultant Y values are evenly distributed away from the x,y line but still remain as close as the interval we specified, limiting their distance away.

*For Model 3:*

Comparing the Model 3 plot with the Model 3 zoomed-in plot above, we can see that the central Y values still have a strong relationship with X, yet the Y outliers are so extreme that a chart displaying all Y values seems to entirely obfuscate the relationship. This is caused by the residual's Cauchy distribution whose outliers radically alter the Y values when added to the model.

The impact of these extreme values is so intense as to reduce the calculated correlation dramatically from and expected 0.64 to ~0.0092.

*For Model 4:*

Again, let's compare the Model 4 plot, this time with our Model 1 plot. The residuals for both these plots utilize a normal distribution, however the Model 4 residuals have a heterogenous standard distribution produced by a process which generated residuals using a different standard deviation for multiple subsets of our 1000 simulated values.

We see that the correlation for this sample is lower, why? Recall that our original Model 1 set of residuals was based on a standard deviation of 1.5 and our heteroscedastic set is based on a standard deviation that fluctuates between 2, 3.4, 0.8, and 2.6. 

We can actually calculate the mean standard deviation of our heteroscendastic set by calculating the mean of the process we created. It is `r mean(hetero.process)`. As 2.18 is a larger deviation than 1.5, we are relieved to see that the correlation is also lower as expected.

What if we were to create a heteroscedastic process of standard deviations with a mean closer to 1.5?

```{r q5-m5}
# Create heteroscedastic process
hetero.sd <- c(1.75, 1.8, 1.4, 2)
hetero.loop <- c(rep(hetero.sd[1], 50),
                 rep(hetero.sd[2], 75),
                 rep(hetero.sd[3], 75),
                 rep(hetero.sd[4], 50))
hetero.process <- rep(hetero.loop, 4)
plot(hetero.process, type = "l")

# Simulate the linear model residuals Eps with changing standard deviations.
set.seed(seed2)
model5.eps <- rnorm(sample.n) * hetero.process

# Simulate the model using X from Model 1 and heteroscedastic residuals
model5.y <- (a * model1.x + b) + model5.eps
model5 <- data.frame(Y=model5.y, X=model1.x, Eps=model5.eps)

# Inspect results
title = "Model 5"
plot(model5$X, model5$Y, main = title, ylim = c(-10, 20))

# Calculate correlation
cor(model5$X, model5$Y)^2
```

Once again we are reassured that the correlation is now even closer to our theoretical 0.64.

## 6. Estimation of Linear Model

Estimate parameters $a, b, \sigma$ using the function lm(). Explore its output.

```{r q6}
model1.est <- lm(Y~X, data = model1)
(model1.summary <- summary(model1.est))

names(model1.summary)
model1.summary$r.squared
model1.summary$coefficients
model1.summary$sigma^2
var(model1.summary$residuals)
```

Note the difference between `r, echo=F summary(m1)$sigma^2` and `r, echo=F var(summary(m1)$residuals)`.

The estimate returned by analyzing the model itself finds $\sigma$ using 2 degrees of freedom (df), or N-2 in the denominator. But `r, echo=F var()` does not know anything about the model and its df. It estimates variance using N-1 in the denominator.

The two estimates are reconciled by $\frac{N-1}{N-2}$.

```{r q6-sigma}
var(model1.summary$residuals) * (sample.n - 1) / (sample.n - 2)
```

### ***Estimate the same parameters using the method of moments directly.***

The method of moments states to first define a set of moments of our population (the model) as functions of our unknown parameters which define the model.

#### 1. Therefore we can define:

$Y = aX + b + \varepsilon$
$Eps \sim Norm(\mu = 0, \sigma = 1.5)$

Expectation of Y, i.e. first moment:

$E[Y] = E[aX + b + \varepsilon]$

$E[Y] = aE[X] + b + E[\varepsilon]$

$E[Y] = aE[X] + b$

Variation of Y, i.e. second central moment:

$Var[Y] = Var[aX + b + \varepsilon]$

$Var[Y] = a^{2}Var[X] + Var[\varepsilon]$

$Var[Y] = a^{2}Var[X] + \sigma_{\varepsilon}^{2}$

Covariance of X & Y:

$\sigma_{XY} = aVar[X]$

#### 2. Using R, we can now solve for our parameters:

```{r q6-mom}
a.est <- cov(model1.x, model1.y) / var(model1.x)
b.est <- mean(model1.y) - (a.est * mean(model1.x))
sigma.est <- sqrt(var(model1.y) - (a.est^2 * var(model1.x)))

c(a.est, b.est, sigma.est)
```

### ***Reconcile our Method of Moments sigma estimate with our sigma obtained through lm().***

???XXX???

## 7. Fit lm() to the the Rest of Linear Models

Compare the differences between the assumptions of the 4 models and tell how they change the model behavior and estimated parameters.

```{r q7}
model2.est <- lm(Y~X, data = model2)
model2.summary <- summary(model2.est)
model3.est <- lm(Y~X, data = model3)
model3.summary <- summary(model3.est)
model4.est <- lm(Y~X, data = model4)
model4.summary <- summary(model4.est)

model2.summary$coefficients
model2.summary$sigma
model2.summary$r.squared
model2.summary$df

model3.summary$coefficients
model3.summary$sigma
model3.summary$r.squared
model3.summary$df

model4.summary$coefficients
model4.summary$sigma
model4.summary$r.squared
model4.summary$df
```

