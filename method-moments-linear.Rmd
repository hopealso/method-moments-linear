---
title: "Statistical Analysis, MSCA 31007, Lecture 3"
author: "Hope Foster-Reyes"
date: "October 28, 2016"
output:
  pdf_document:
    fig_width: 6.5
    fig_height: 4.5
geometry: margin=0.75in
---

# Simulation of 4 Linear Models

Understand common assumptions behind the linear model.

_Notes_

* _Style Guide:_ https://google.github.io/styleguide/Rguide.xml

* _Packages required: None_

* _Files required: None_

## Set Up

Set the values of slope (a) and intercept (b) parameters. Set the sample length to 1,000.

```{r setup}
# Slope and Intercept
a <- 0.8; b <- 0.1
sample.n <- 1000

# Seeds
seed1 <- 111
seed2 <- 1112131415

options(scipen = 5)
```

## Model 1.

Simulate and plot Model 1:

Input variable $X \sim Norm(\mu= 3, \sigma=2.5)$; model residuals $Eps \sim Norm(\mu = 0, \sigma = 1.5)$

```{r m1, fig.width=6.5, fig.height=4.5}
# Simulate the model using rnorm() for X and Eps
set.seed(seed1)
model1.x.sd <- 2.5
model1.x <- rnorm(sample.n, mean = 3, sd = model1.x.sd)
set.seed(seed2)
model1.eps.sd <- 1.5
model1.eps <- rnorm(sample.n, mean = 0, sd = model1.eps.sd)

model1.y <- (a * model1.x + b) + model1.eps
model1 <- data.frame(Y=model1.y, X=model1.x, Eps=model1.eps)

# Inspect results
title <- "Model 1"
head(model1)
plot(model1$X, model1$Y, main = title)
plot(model1$Eps, type = "l", main = paste(title, "Residuals"))
```

## Model 2.

Simulate and plot Model 2:

Input variable $X \sim Norm(\mu= 3, \sigma=2.5)$; model residuals $Eps \sim Unif(min=-4.33, max=4.33)$

```{r m2}
# Simulate the model using X from Model 1 and runif() for Eps
set.seed(seed2)
model2.eps <- runif(sample.n, min = -4.33, max = 4.33)

model2.y <- (a * model1.x + b) + model2.eps
model2 <- data.frame(Y=model2.y, X=model1.x, Eps=model2.eps)

# Inspect results
title <- "Model 2"
head(model2)
plot(model2$X, model2$Y, main = title)
plot(model2$Eps, type = "l", main = paste(title, "Residuals"))
```

## Model 3.

Simulate and plot Model 3:

Input variable $X \sim Norm(\mu= 3, \sigma=2.5)$; model residuals $Eps \sim Cauchy*(location=0, scale=3)$

```{r m3}
# Simulate the model using X from Model 1 and rcauchy() for Eps
set.seed(seed2)
model3.eps <- rcauchy(sample.n, location = 0, scale = 0.3)

model3.y <- (a * model1.x + b) + model3.eps
model3 <- data.frame(Y=model3.y, X=model1.x, Eps=model3.eps)

# Inspect results
title <- "Model 3"
head(model3)
plot(model3$X, model3$Y, main = title)
plot(model3$Eps, type = "l", main = paste(title, "Residuals"))
```

Estimate the standard deviation of the residuals

```{r m3-sd}
(sd(model3$Eps))
```

Generate another 5 samples of residuals without any seed specification and estimate standard deviations for each of them.

```{r m3-residuals}
model3.eps1 <- rcauchy(sample.n, location = 0, scale = 0.3)
model3.eps2 <- rcauchy(sample.n, location = 0, scale = 0.3)
model3.eps3 <- rcauchy(sample.n, location = 0, scale = 0.3)
model3.eps4 <- rcauchy(sample.n, location = 0, scale = 0.3)
model3.eps5 <- rcauchy(sample.n, location = 0, scale = 0.3)
c(sd(model3.eps1), sd(model3.eps2), sd(model3.eps3), sd(model3.eps4), sd(model3.eps5))
```

Note the irregularity of standard deviations from sample to sample.

***How do you interpret this observation?***

The Cauchy distribution is unique in that its expected value, i.e. mean, and other moments of any order n >= 1 do not exist. For example, in contrast with a Cauchy, for the normal distribution we can define parameters which will result in theoretical moments. For any sample based on this specific distribution (i.e. these specific parameters), the sample will demonstrate moments (which may be calculated using its moment generating function) which are similar to the theoretical moments, and which, as the sample becomes larger and larger, will converge on those moments.

Unlike the normal distribution and other typical families of distributions, the Cauchy family of distributions does not demonstrate this same quality. There is no moment generating function and therefore no theoretical moments. While we may still calculate a number for the mean or standard deviation of an individual sample using the common formulas, these numbers will not bear any consistency or resemblance to any theoretical mean or standard deviation, as for Cauchy distributions these do not exist.

## Model 4.

Simulate and plot Model 4:

Input variable $X \sim Norm(\mu= 3, \sigma=2.5)$; model residuals $Eps \sim$ a heteroscedastic process.

Heteroscedasticity means that even though the model residuals Eps may be generated by a normal distribution, the standard deviation parameters for different sub samples are different.

Create the process of standard deviations in which the first 50 observations have sigma=2, followed by 75 observations with sigma=3.4, followed by 75 observations with sigma=0.8 and concluded by 50 observations with sigma=2.6.

Plot the trajectory of standard deviations of total length nSample=1000.

```{r m4-residuals}
# Create heteroscedastic process
hetero.sd <- c(2, 3.4, 0.8, 2.6)
hetero.loop <- c(rep(hetero.sd[1], 50),
                 rep(hetero.sd[2], 75),
                 rep(hetero.sd[3], 75),
                 rep(hetero.sd[4], 50))
hetero.process <- rep(hetero.loop, 4)
plot(hetero.process, type = "l")

# Simulate the linear model residuals Eps with changing standard deviations.
set.seed(seed2)
model4.eps <- rnorm(sample.n) * hetero.process

# Plot the residuals
title <- "Model 4"
plot(model4.eps, type = "l", main = paste(title, "Residuals"))
```

Observe how heteroscedasticity transforms normal distribution into leptokurtic distribution.

```{r m4-demo}
hetero.x <- (100 * floor(min(model4.eps))) : (100 * ceiling(max(model4.eps)))
hetero.x <- hetero.x / 100

# Plot the theoretical distribution
plot(hetero.x, dnorm(hetero.x, mean = mean(model4.eps), sd = sd(model4.eps)), 
     type = "l", ylim = c(0, 0.3), col = "black", 
     ylab = "Distribution of Heteroscedastic Eps")

# And the heteroscedastic sample distribution
lines(density(model4.eps), col = "Red")
```

Generate Model 4 and plot.

```{r m4}
model4.y <- (a * model1.x + b) + model4.eps
model4 <- data.frame(Y=model4.y, X=model1.x, Eps=model4.eps)

# Inspect results
plot(model4$X, model4$Y, main = title)
```

## Effect of Residual Distribution on Correlation

Calculate the theoretical $\rho^{2}$ for the “correct model” which is Model 1.

```{r q5}
# Calculate squared correlation coefficient using the parameters specified 
#   for Model 1 X and Eps
(rho.sq.theoretical <- (a * model1.x.sd)^2 / ((a * model1.x.sd)^2 + model1.eps.sd^2))
```

And compare with the estimated $\rho^{2}$

c(cor(model1$X, model1$Y)^2,
  cor(model2$X, model2$Y)^2,
  cor(model3$X, model3$Y)^2,
  cor(model4$X, model4$Y)^2)
  
***How do you interpret the results?***